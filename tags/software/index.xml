<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Software on All in Camera</title>
    <link>http://allincamera.github.io/tags/software/</link>
    <description>Recent content in Software on All in Camera</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 30 Apr 2016 00:44:57 +0800</lastBuildDate>
    <atom:link href="http://allincamera.github.io/tags/software/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>【科普】双摄像头能做什么？</title>
      <link>http://allincamera.github.io/post/dual_cam_intro_01/</link>
      <pubDate>Sat, 30 Apr 2016 00:44:57 +0800</pubDate>
      
      <guid>http://allincamera.github.io/post/dual_cam_intro_01/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;本文系微信公众号『大话成像』，知乎专栏『all in camera』原创文章，转载请注明出处并保留本声明&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;目前主流的双摄像头的功能。主要可以分为两大类：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;利用双摄像头产生立体视觉，获得影像的景深。以及利用将不同的景深进行3D建模，图像处理，物体分割，物体识别和跟踪，对焦辅助之类的功能&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;利用左右两张不同的图片信息进行融合，以期望得到更高的分辨率，更好的色彩，动态范围等更好的图像质量。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两类双摄像头功能对于摄像头的硬件有着不同的要求，前者要求两个摄像头得到像差尽量大，这样能够得到的景深精度更高，因此前者的硬件希望两个摄像头间的距离比较远才好。而后者希望两个摄像头的像在空间和时间上都尽量能够接近，因此在硬件设计的时候希望两个摄像头离得比较近。这样在两个图像融合的时候才不会因为相差产生更多的错误。&lt;/p&gt;

&lt;p&gt;但是由于摄像头无法做的完全一致。因此无论是这两类功能的哪一类，算法都希望能在得到图像的同时，能够更多的得到硬件的实际情况如：姿势差和两个摄像头的镜头畸变等。而这些信息需要平台算法和模组生产手机生产使用相同且方便于工程化的算法进行计算，很多牵扯到硬件本身的特性，不是简单从理论计算就能解决的。以后有时间我们会继续讨论这个话题。总之双摄像头的使用过程中算法和硬件本身结合的十分紧密，不可分割。因此说到双摄像头现在首先应该关注的应该是双摄像头能带来什么样的用户体验。双摄像头中对软件硬件结合的要求远比单摄像头要高。而我们在看到一款使用双摄像头的手机的时候从它的硬件设计就能看出它是偏重于哪一类功能。下图就是常见的两个摄像头在姿势差上面的信息。就是针对3D坐标轴XYZ的平移和旋转。后面面我们把双摄像头的能实现功能给大家介绍。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/dualcam_module.png&#34; alt=&#34;Dual Cam Module&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;景深应用:681b06908344f27af169accd314408b0&#34;&gt;景深应用&lt;/h2&gt;

&lt;p&gt;第一类功能首先要获得当前场景的景深图。其基本原理就是基于三角定位。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/depth_calc.jpg&#34; alt=&#34;Depth Calc&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;背景虚化:681b06908344f27af169accd314408b0&#34;&gt;背景虚化&lt;/h3&gt;

&lt;p&gt;第一类功能中最典型的就是背景虚化，在景深图的基础上将不同距离的物体进行虚化，模拟大光圈相机拍摄效果。&lt;/p&gt;

&lt;p&gt;该功能在以前的双camera中经常能见到，如HTC的后置双摄和联想前置双摄S1。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/depth_blur.jpg&#34; alt=&#34;Depth Blur&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;物体分割:681b06908344f27af169accd314408b0&#34;&gt;物体分割&lt;/h3&gt;

&lt;p&gt;目前在手机上主要用于图片的裁减，和背景替换，利用景深信息可以更好的可以将不同景深的物体分割开。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/depth_split.png&#34; alt=&#34;Depth Split&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3d扫描:681b06908344f27af169accd314408b0&#34;&gt;3D扫描&lt;/h3&gt;

&lt;p&gt;通过不同角度下的景深图进行建模。这对景深图和算法的要求比较高。手机上的双camera之间的距离有限往往能够得到的景深图的精度不够好，景深信息处理算法复杂在手机硬件上计算的时间长，因此目前这个功能在手机上面基本没有。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/3d_model.png&#34; alt=&#34;3D Scanning&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;目标物体距离计算和快速对焦:681b06908344f27af169accd314408b0&#34;&gt;目标物体距离计算和快速对焦&lt;/h3&gt;

&lt;p&gt;利用三角定位计算景深的最简单的应用&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/fast_focus.png&#34; alt=&#34;fast focus&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3d视频及照片制作:681b06908344f27af169accd314408b0&#34;&gt;3D视频及照片制作&lt;/h3&gt;

&lt;p&gt;不同于一般的3D电影的拍摄。手机上的两个摄像头无法在图像的拍摄过程中就产生足够的视觉差，这是由于两个摄像头中间的距离和人眼不一样。而且为了能够让人们更明显的得到3D视觉效果。所以往往需要算法进行增强。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/3d_video.jpg&#34; alt=&#34;3D Photo&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ar增强和动作识别:681b06908344f27af169accd314408b0&#34;&gt;AR增强和动作识别&lt;/h3&gt;

&lt;p&gt;主要是利用两个摄像头进行手势或者姿势的识别。目前在市场上比较常见的就是leap motion 还有微软的 Kinect 都是类似的功能。亚马逊fire phone 曾经尝试在手机上实现类似的功能，但是最终手机的供电以及空间并没有给用户良好的体验。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/3d_gesture.jpg&#34; alt=&#34;3D Gesture&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;图像合成:681b06908344f27af169accd314408b0&#34;&gt;图像合成&lt;/h2&gt;

&lt;p&gt;第二类功能都是通过将不同的图片中的不同的信息，合成到一张图片中，使合成之后的图片得到更好的效果。此类应用硬件设计中就会注意如何分别提供不同的信息。&lt;/p&gt;

&lt;h3 id=&#34;超分辨率:681b06908344f27af169accd314408b0&#34;&gt;超分辨率&lt;/h3&gt;

&lt;p&gt;主要是利用多张图片中在高频部分不同的内容生成一张清晰的图片，双camera可以通过两张照片中不同的信息进行最后的增强。&lt;/p&gt;

&lt;p&gt;然而传统算法生成需要的图片一般都是需要更多的图片，两张图片能够提供的不同信息还是太少，如华为的Mate6 plus号称是两颗8M可以合成13M的图像，但是实际拍摄的图像的解析力还只是8M的水平，和我们自己缩放一张图片并没有什么区别。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;有关解析力的区别可参阅往期解析力测试相关内容&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/super_resolution.jpg&#34; alt=&#34;Super Resolution&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;hdr:681b06908344f27af169accd314408b0&#34;&gt;HDR&lt;/h3&gt;

&lt;p&gt;对两个Camera设置不同的曝光参数以得到不同曝光参数的图像进行HDR合成。&lt;/p&gt;

&lt;p&gt;以往这个功能需要通过以往一个摄像头去修改曝光时间来得到不同曝光情况下的图片，但是这种办法需要的时间长。这不仅导致了用户体验变差，且如果场景中有运动物体或者相机有移动的话会导致鬼影的问题。利用双camera则能避免类似的问题。但是大多数合成的过程中多数的HDR算法主要关注于亮度信息，多数的算法在颜色方面会有些失真。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/hdr.wm.png&#34; alt=&#34;HDR Sample&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;低光提亮和去噪:681b06908344f27af169accd314408b0&#34;&gt;低光提亮和去噪&lt;/h3&gt;

&lt;p&gt;低光提亮和去噪在算法上和HDR基本没有区别。主要是利用两颗摄像头中一颗&lt;strong&gt;黑白摄像头&lt;/strong&gt;的低光下响应较好噪声较小的特性。&lt;/p&gt;

&lt;p&gt;其优点是对于彩噪有不错的抑制性一般能够3个DB左右的SNR提高，但是实际拍摄的图片多数情况下效果提升有限，和有些在低光下做过特殊处理和tuning的单camera系统比并没有很明显的优势。&lt;/p&gt;

&lt;p&gt;华为P9这一次主要就采用了这种camera的设计，从多数我们看到的网上的评价来看目前在低光下的效果有改进但并不惊艳。在华为P9之前，奇酷也采用类似的硬件设计实现这个功能。&lt;/p&gt;

&lt;p&gt;这个功能目前看给用户的提升很有限，也许后面还有挖掘的潜力。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/low_light.wm.png&#34; alt=&#34;Low Light&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;光学变焦:681b06908344f27af169accd314408b0&#34;&gt;光学变焦&lt;/h3&gt;

&lt;p&gt;最近比较好的应用趋势是利用一颗正常的FOV的摄像头模组和一颗远焦镜头的模组达到光学变焦的效果。&lt;/p&gt;

&lt;p&gt;从苹果收购以色列的Linx公司还有苹果公司最新公布的专利来看，水果公司最新的专利来看这个功能很可能是水果公司的双camera的主要功能。远焦镜头的视场角要比正常的镜头小很多，但是相同距离下图片的解析力也会高不少。利用远焦镜头可以提供的较好的分辨率既可以在平时拍照的时候利用融合算法提高中心区域的分辨率，也可以在变焦时利用远焦的照片提高ZOOM后的解析力。从之前看到过的另外一家以色列公司CP的算法效果来看，如果手机上实现的好的话可能在中心区域超过现有手机摄像头最大的解析力，在效果上和光学zoom相差不大。虽然这个功能在硬件设计的时候有着远焦模组过高的问题，但是这依然是第二类功能中目前能看到效果最好的功能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/dual_cam_intro_01/optical_zoom.jpg&#34; alt=&#34;Optical Zoom&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;现状总结:681b06908344f27af169accd314408b0&#34;&gt;现状总结&lt;/h2&gt;

&lt;p&gt;从目前市面上能看到双Camera手机来看：&lt;/p&gt;

&lt;p&gt;偏景深类功能的手机目前主要的问题是景深信息不够准确计算速度慢。无法实时得到景深信息。不过目前手机硬件的发展速度很快，很多ISP的设计已经开始考虑双camera的实时景深。今年很多实时景深的ISP将开始在平台端普及，虽然分辨率还不是很理想。但是随着实时景深的普及，景深信息的分辨率的增加，相信后面利用景深信息实现的场景物体识别类的功能相信会越来越多。类似我们之前看电影中的一些现实增强的效果我相信 也会越来越多。而且这类功能在智能机器人领域也是目前的热门。如陪李总理的打球的机械人就是这类功能的延伸。不过进入平常百姓家这个肯定需要时间。&lt;/p&gt;

&lt;p&gt;而偏第二类图片融合得到更好图像质量的功能，从目前已有的手机来看都不是很成功。不过实现光学变焦的效果从算法效果的层面上来看效果很不错,或许苹果的双摄出来之后能在这个领域带起一个风潮。&lt;/p&gt;

&lt;p&gt;两类应用对摄像头模组要求是不同的，前者要求模组间的距离较大为好，后者则要求模组间的距离尽量小。虽然无论做的多小但由于模组本身的尺寸，两个摄像头间肯定会有些距离的。比如华为P9两个摄像头间的距离已经小于1厘米，但是再想做的更小可能需要突破性的设计。&lt;/p&gt;

&lt;p&gt;当然，为其中一类功能设计的双摄像头模组也可以实现另外一类功能，只是勉强实现会增加算法的复杂程度，在最终实现的效果上也会受到很大制约。比如P9虽然也实现了景深功能但效果和专门为景深功能功能设计的双摄像头比还是很有差距的。&lt;/p&gt;

&lt;p&gt;双摄像头的风潮刚刚开始，后续我们会邀请不同领域的专家来介绍双摄像头实现的一些具体问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本文系微信公众号『大话成像』，知乎专栏『all in camera』原创文章，转载请注明出处并保留本声明&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>图解噪声与去噪 之二：从『均值滤波』到『BM3D』</title>
      <link>http://allincamera.github.io/post/noise_and_denoise2/</link>
      <pubDate>Fri, 29 Apr 2016 17:14:30 +0800</pubDate>
      
      <guid>http://allincamera.github.io/post/noise_and_denoise2/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;本文系微信公众号《大话成像》，知乎专栏《大话成像 all in camera》原创文章，转载请注明出处。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上一篇讲过了temporal noise和Fix patter noise的分离，通过多帧平均可以去除掉temporal noise，并分离出FPN，在这篇将介绍如何去除FPN。&lt;/p&gt;

&lt;p&gt;在信号处理教科书中，介绍过很多经典的图像去噪方法，主要的是针对随机噪声的，对于图像中非随机噪声，比如sensor本身的物理缺陷导致的hot pixel，weak pixel 或是dead pixel，一般称之为impulse noise，对于impulse noise有单独的处理方法，因为他们不属于随机噪声。&lt;/p&gt;

&lt;p&gt;随机噪声也就是在比图像的真实信号或高或低的不确定变化。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/random_noise.png&#34; alt=&#34;random noise&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果中间的虚线视作真实信号，红色和蓝色的曲线代表随机噪声叠加后的信号，如果虚线定义为0，那么所有随机噪声求和应为0 ，在统计学上叫零和噪声。由于零和噪声的这种特点，均值滤波可以降低图像的噪声。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/random_noise_average_value.png&#34; alt=&#34;random noise average value&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如图所示，浅蓝色的线代表红蓝线求均值以后的信号，波动的幅度明显减小了，也就是噪声降低了。&lt;/p&gt;

&lt;h2 id=&#34;均值滤波与变换域去噪:f2f70d1c93bc2130230de88cd673ff17&#34;&gt;均值滤波与变换域去噪&lt;/h2&gt;

&lt;p&gt;教科书里讲图像去噪声，第一个提到的就是均值滤波，在图像处理中，就是当前像素的值用周围n个像素的均值来代替。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/local_average_formula.png&#34; alt=&#34;local average formula&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在实际信号处理中，就是用一个n x n 的模版 A 对图像进行卷积，比如：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/local_avg_filter.png&#34; alt=&#34;local average filter&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当前像素就是处在矩阵中心的像素，它的值等于周围所有像素的值包括它自身取均值。&lt;/p&gt;

&lt;p&gt;这样的一个基本均值滤波，它可以去掉噪声，但同时也会把图像搞模糊，比如当前的像素正好是一个图案的边缘，左边是白色的，像素值是200，右边是黑色的，像素值是10，做完均值滤波，（200+200+200+10+10+10+10+10+10）/9 = 74， 这样图像的细节就被模糊掉了。于是人们就对这种均值滤波进行了一些改进，比如增加图像边缘方向的判断，红线的方向上相邻像素的数值差不多，所以在做均值的时候只把这个方向的两个像素计算在内。这样既去掉了一些噪声，又保持了锐度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/pixel_array.png&#34; alt=&#34;pixel array&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这样由于做均值的像素变少了，去噪的效果不太好，于是有人想出一种none local mean的方法，也就是做均值的像素不再是领域的像素，扩大些范围找相似的，然后再做均值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/none_local_mean.png&#34; alt=&#34;none local mean value&#34; /&gt;&lt;/p&gt;

&lt;p&gt;绿色的部分和中心要处理的部分很相似，求均值的时候就把这些部分算进去，而红色的部分不相似，去均值的时候就排除这些部分。很容易想象，搜索的范围越大，计算量越大。&lt;/p&gt;

&lt;p&gt;这些方法都是从空间的角度去思考如何去噪，也就是所谓的spatial noise reduction，这条路子能想的方法也都做得差不多了，于是有人换个角度想问题，就有了变换域做去噪的方法。通过数学变换，在变换域上把信号和噪声分离，然后把噪声过滤掉，剩下的就是信号。如下图，&lt;/p&gt;

&lt;p&gt;没有噪声的信号看起来比较光滑：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/signal_wo_noise.png&#34; alt=&#34;signal no noise&#34; /&gt;&lt;/p&gt;

&lt;p&gt;带噪声的信号就会有些毛刺：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/signal_with_noise_glitch.png&#34; alt=&#34;signal with noise glitch&#34; /&gt;&lt;/p&gt;

&lt;p&gt;把带噪声的信号变换到一个域（比如频域，小波域等等)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/signal_noise_trans.png&#34; alt=&#34;signal noise trans&#34; /&gt;&lt;/p&gt;

&lt;p&gt;高于一个阈值的部分就是噪声，设一个截止值，把高于截止值的部分去掉&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/signal_noise_trans_threshold.png&#34; alt=&#34;signal noise trans threshold&#34; /&gt;&lt;/p&gt;

&lt;p&gt;再做反变换，就得到了干净的信号。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/signal_trans_back.png&#34; alt=&#34;signal trans back&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从频率上可以把噪声分为高中低频噪声，用这种变换域的方法就可以把不同频率的噪声分离，然后有效的去掉。像傅立叶变换，小波变换都是比较常见的变换域方法。&lt;/p&gt;

&lt;h2 id=&#34;bm3d去噪:f2f70d1c93bc2130230de88cd673ff17&#34;&gt;BM3D去噪&lt;/h2&gt;

&lt;p&gt;简单来说，BM3D融合了spatial denoise和tranform denoise，可以得到最高的峰值信噪比。它先吸取了NLM中的计算相似块的方法，然后又融合了小波变换域去噪的方法。这是芬兰Tampere工业大学在2007年发表的论文里提出的算法。（了解NOKIA的人就知道Tampere这个城市就是NOKIA最早起源的地方）。&lt;/p&gt;

&lt;p&gt;具体算法如下：&lt;/p&gt;

&lt;p&gt;第一步，搜索相似块，然后把相似的块grouping成一个个3D stack。（图像本身是2D，变成stack就成了3D）&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/bm3d1_wm.png&#34; alt=&#34;BM3D Step1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第二步，把这些3D stack进行变换域&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/bm3d2_wm.png&#34; alt=&#34;BM3D Step2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第三步，3D 协同滤波&amp;mdash;-听着很邪乎，细节需要自行wiki&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/bm3d3_wm.png&#34; alt=&#34;BM3D Step3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;第四步，反变换以及blending&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/avg2bm3d/bm3d4_wm.png&#34; alt=&#34;BM3D Step4&#34; /&gt;&lt;/p&gt;

&lt;p&gt;红色模块里提到的在变换域中thresholding的设定，有自适应计算的方法，但在工程中用的效果比较好的是噪声模型法，关于噪声模型，我们会在下一篇中进行介绍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本文系微信公众号《大话成像》，知乎专栏《大话成像 all in camera》原创文章，转载请注明出处。&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>图解噪声与去噪 之一： fix pattern noise（FPN）与 temporal noise</title>
      <link>http://allincamera.github.io/post/noise_and_denoise1/</link>
      <pubDate>Tue, 19 Apr 2016 18:55:14 +0800</pubDate>
      
      <guid>http://allincamera.github.io/post/noise_and_denoise1/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;本文系微信公众号《大话成像》，知乎专栏《大话成像 all in camera》原创文章，转载请注明出处。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;噪声分类:a6abbaf212851257f798600f7bb6b968&#34;&gt;噪声分类&lt;/h2&gt;

&lt;p&gt;噪声有很多种分类方法，比如从频率上分，可以分为高频，中频，低频噪声。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/no_noise.label.png&#34; alt=&#34;No Noise&#34; /&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/high_freq_noise.label.png&#34; alt=&#34;High Frequency Noise&#34; /&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/mid_freq_noise.label.png&#34; alt=&#34;Mid Frequency Noise&#34; /&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/low_frequency_noise.label.png&#34; alt=&#34;Low Frequency Noise&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从色彩空间上分，可以分为luma noise亮度噪声与chroma noise彩色噪声。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/luma_chroma_noise.wm.jpg&#34; alt=&#34;Luma Chroma Noise&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从时态上分，可以分为fix pattern noise与temporal noise。Fix pattern noise 与时间无关，表现上看就是噪声幅度不随时间变化。Temporal noise是随时间变化，在低光下录制的视频中不断变化的细小信号就是temporal noise。&lt;/p&gt;

&lt;p&gt;也有的分法把fix pattern noise定义为在图像行或者列存在的一条条的噪声，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/fix_pattern_noise.label.png&#34; alt=&#34;Fix Pattern Noise&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Temporal noise视觉上是一种高频噪声。&lt;/p&gt;

&lt;h2 id=&#34;噪声计算:a6abbaf212851257f798600f7bb6b968&#34;&gt;噪声计算&lt;/h2&gt;

&lt;p&gt;均值 &lt;code&gt;$\mu = \dfrac {\sum^{n}_{i=1}X_{i}}{n}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;标准差 &lt;code&gt;$\sigma=\dfrac {1}{n-1}\sum ^{n}_{i=1}\left(u-x{i}\right)^{2}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;图像的标准差可以作为图像噪声水平的评价值。&lt;/p&gt;

&lt;p&gt;按照如下曝光时间，每个曝光时间拍30张black 照片。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-matlab&#34;&gt;	exp_time = [0.063, 1.003,16, 64,257,513,770,1027,1283,1540,1797,2054];
	raw_avg = 0;
	for kk = 0:30:(30*12-1)
	    for i = 1:30
	        fname = fileNames{kk+i};      
	        fprintf(&#39;processing %s %d\n&#39;, fname, kk+i);
	        raw = double(imread([fold fname]));
	        raw = raw(:,:,1);
	        raw_avg = raw + raw_avg;  
	    end
	    raw_avg = raw_avg./30; 
	    
	    avg_signal((kk/30)+1) = round(mean2(raw_avg));
	    fpn_total((kk/30)+1) = std2(raw_avg);
	     
	    fpn_col_exp((kk/30)+1) = std(mean(raw_avg,1));
	%     avg_sig_col_exp((kk/30)+1,:) = mean(raw_avg,1);
	    
	    fpn_row_exp((kk/30)+1)     = std(mean(raw_avg,2)&#39;);
	%     avg_sig_row_exp((kk/30)+1) = mean(raw_avg,2)&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如上计算，可以得到图像的平均信号，每个曝光的FPN noise，以及行，列FPN noise,行列均值。
&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/avg_sig_total_fpn.wm.png&#34; alt=&#34;Average Signal and total FPN&#34; /&gt;&lt;/p&gt;

&lt;p&gt;把曝光逐渐增加，确保图像能够达到饱和，在10个曝光值，每个曝光值下拍30张flat field照片&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-matlab&#34;&gt;	raw_avg = 0;
	temp_noise = zeros(30,480*752);
	for kk = 0:30:(30*11-1)
	    for i = 1:30
	        fname = fileNames{kk+i};
	        fprintf(&#39;processing %s %d\n&#39;, fname, kk+i);
	        raw = double(imread([fold fname]));
	        raw = raw(:,:,1);
	        raw_avg = raw + raw_avg;
	        temp_noise(i,:) = raw(:)&#39;;
	    end
	    raw_avg = raw_avg./30;
	    
	    std_temp_noise = std(temp_noise,1);
	    
	    avg_signal((kk/30)+1) = round(mean2(raw_avg));
	    temporal_total((kk/30)+1) = median(std_temp_noise);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如上计算，可以得到图像的temporal noise&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/total_temporal.wm.png&#34; alt=&#34;Total Temporal&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最后图像饱和，所以噪声降低至0。&lt;/p&gt;

&lt;p&gt;FPN noise是相关噪声，temporal noise是不相关噪声。&lt;/p&gt;

&lt;p&gt;两个图像相加：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$S = S_1 + S_2$&lt;/code&gt; S代表信号&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$\sigma^{2}_{t}=\sigma^{2}_{t1}+\sigma^{2}_{t2}$&lt;/code&gt; &lt;code&gt;$\sigma_{t}$&lt;/code&gt; 代表temporal noise&lt;/p&gt;

&lt;p&gt;信噪比SNR &lt;code&gt;$\dfrac {S}{\sigma_{t}}=\dfrac {S_{1}+S_{2}}{\left(\sigma^{2}_{t1}+\sigma^{2}_{t2}\right)^{0.5}}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当 &lt;code&gt;$S_{1} = S_{2}$&lt;/code&gt; , &lt;code&gt;$\sigma_{t1} = \sigma_{t2}$&lt;/code&gt;, 信噪比SNR &lt;code&gt;$\dfrac {S}{\sigma_{t}}=2^{0.5}\dfrac{S_{1}}{\sigma_{t1}}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当 &lt;code&gt;$S_{1} = S_{2}=...=S_{n}$&lt;/code&gt; , 信噪比SNR &lt;code&gt;$\dfrac {S}{\sigma_{t}}=n^{0.5}\dfrac{S_{1}}{\sigma_{t1}}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;该公式从理论上证明了n帧平均会降低temporal noise &lt;code&gt;$n^{0.5}$&lt;/code&gt; 倍。所以信号处理中去除temporal noise的方法就是多帧平均加运动检测，如果存在图像存在变化就不累加，如果图像无变化就累加平均。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/allincamera/imgur/master/noise_and_denoise1/frame_average.wm.png&#34; alt=&#34;Frame Average&#34; /&gt;&lt;/p&gt;

&lt;p&gt;而FPN noise 是相关噪声&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$\sigma_{fpn} = \sigma_{fpn1} + \sigma_{fpn2}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$S = S_{1} + S_{2}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ \dfrac {S}{\sigma_{fpn}} = \dfrac {S_{1}+S_{2}}{\sigma_{fpn1}+\sigma_{fpn2}} $&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当 &lt;code&gt;$ S_{1} = S_{2} $&lt;/code&gt;, &lt;code&gt;$ \sigma_{fpn1} = \sigma_{fpn2} $&lt;/code&gt; 时， &lt;code&gt;$ \dfrac {S}{\sigma_{fpn}} = \dfrac {S_{1}}{\sigma_{fpn1}} $&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;多帧平均不会降低FPN。&lt;/p&gt;

&lt;p&gt;通过上图可以看出，经过多帧平均后，噪声的floor变成了FPN。&lt;/p&gt;

&lt;p&gt;通过多帧平均可以分离temporal noise和FPN，然后用其他信号处理的方法去除FPN，下一篇将介绍去噪的Spacial domain 和 transform domain的方法。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>